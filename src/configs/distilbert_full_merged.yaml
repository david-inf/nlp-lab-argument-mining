batch_size: 32
checkpoint: src/ckpts/distilbert_full_merged
checkpoint_dir: src/ckpts
checkpoint_every: null
config_file: src/configs/distilbert_full_merged.yaml
dataset: merged
early_stopping:
  min_delta: 0.001
  patience: 7
experiment_name: distilbert_full_merged
ft_setting:
  ftname: full
  lr_backbone: 5.0e-05
  lr_head: 0.0001
  type: full
  warmup: 0.05
  weight_decay: 0.01
log_every: 20
max_length: 128
model: distilbert
num_epochs: 50
num_workers: 4
seed: 42
visualize: false
